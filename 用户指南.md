## 目录
- 1、shark入门；<br>
   - 1.1 dataBase架构演变史；<br>
   - 1.2 sharding与cluster的区别；<br>
   - 1.3 shark简介；<br>
   - 1.4 常见的sharding中间件对比；<br>
   - 1.5 从maven中央仓库下载shark的构件；<br>
   - 1.6 shark依赖的其它maven构件；<br>
   - 1.7 下载并编译shark源码；<br>
   - 1.8 shark的架构模型；<br>
   - 1.9 shark的分片算法；<br>
   - 1.10 单表查询支持的sql模板；<br>
   - 1.11 shark使用过程中的一些注意事项；<br>
- 2、配置读写分离操作；<br>
   - 2.1、sql编写注意事项；<br>
- 3、配置sharding操作；<br>
   - 3.1 数据库sharding后带来的影响；<br>
   - 3.2 配置sql文件与逻辑代码结构；<br>
   - 3.3 一库一片算法；<br>
       - 3.3.1 片名连续的一库一片操作；<br>
       - 3.3.2 非片名连续的一库一片操作；<br>
   - 3.4 库内分片算法；<br>
       - 3.4.1 片名连续的库内分片操作；<br>
       - 3.4.2 非片名连续的库内分片操作；<br>
   - 3.5 自动生成数据源文件；<br>
       - 3.5.1 自动生成sharding配置文件
       - 3.5.2 自动生成c3p0数据源文件；<br>
       - 3.5.3 自动生成druid数据源文件；<br>
   - 3.6 多机sequenceid解决方案；<br>
       - 3.6.1 基于mysql生成全局唯一sequenceid；<br>
       - 3.6.2 基于zookeeper生成全局唯一sequenceid；<br>
   - 3.7 事物功能矩阵；<br>
- 4、使用配置中心；<br>
   - 4.1 基于zookeeper的资源配置中心；<br>
   - 4.2 基于redis3 cluster的资源配置中心；<br>
       - 4.2.1 使用版本号比对资源差异；<br>
       - 4.2.2 使用md5码比对资源差异；<br>
- 5、运维监控；<br>
   - 5.1 配置shark内置验证页面；<br>
- 6、HA方案；<br>
   - 6.1 基于配置中心实现HA；<br>
   - 6.2 基于keepalive实现HA；<br>
   - 6.3 基于MHA实现HA；<br>

## 1、shark入门
本篇作为本文的开篇，笔者衷心希望能够用干练的语句将shark的各个技术点尽可能的阐述清楚。

## 1.1 dataBase架构演变史
对于刚上线的互联网项目来说，由于前期用户活跃度并不大，并发量相对较小，因此企业一般都会选择将所有数据信息存放在单库中进行读/写操作。随着用户活跃度的不断提升，单库逐渐力不从心，这时DBA就会将数据库设置为读写分离状态(一主一从/一主多从)，Master负责写，Slave负责读。按照二八定律，80%的操作更多是读，那么剩下的20%则为写，读写分离后，大大提升了单库无法支撑的负载压力。不过光靠读写分离并不能一劳永逸，随着用户活跃度再次提升，必然会遇见读/写瓶颈，因此到了这个阶段，DBA就需要实现垂直分库。

所谓垂直分库，就是根据业务划分将原本冗余在单库中的数据表分拆，落到不同的业务库中，实现分而治之。垂直分库能够有效提升数据库的并行处理能力，但是单一业务的数据信息仍然落盘在单表中，理论上Mysql单表超过500W行时，读操作就会成为瓶颈，哪怕重建索引，也无法解决数据暴增带来的检索效率低下等问题。这其实也是RDBMS等类型数据库的特点，相对于Nosql数据库而言，由于底层存储架构不同，所以自然无法相提并论。因此到了这个阶段，DBA就需要在垂直分库的基础上实现水平分区，也就是大家常说的数据sharding操作。

所谓水平分区，就是将原本冗余在单库中的单表分拆为N个“逻辑相连”的子表(比如tab_0000、tab_0001、tab_N...)，比如tab_0000存储1-10000区间的数据信息，而tab_0001存储10001-20000区间的数据信息。如果希望采用分布式分片，则可以将单库也拆分为N个“逻辑相连”的子库(比如db_0000、db_0001、db_n...)，一个子库中可以包含单个或N个子表。假设分库分表后，子表的数据量又达到阈值时，DBA只需要横向扩容即可。基于分库分表的数据库设计，目前在国内一些大型互联网企业中应用的非常普遍，比如：阿里巴巴、京东、云集微店等。

最后简单总结一下，分库分表主要是为了解决单库性能瓶颈，充分利用分布式+集群的威力提升数据库的读/写性能。关于互联网场景下常见的性能瓶颈：
- 大量的并发访问，导致单库出现难以承受的负载压力；
- 单表数据量过大，导致检索效率低下；

## 1.2 sharding与cluster的区别
单纯从技术上来讲，Mysql Cluster仅仅只是一个数据库集群，其优势只是扩展了数据库的并行处理能力，但使用成本、维护成本相当高(目前使用者很少，实施也相对复杂)。而Sharding是一个成熟且实惠的方案，不仅可以解决数据库的并行处理能力，还能够解决单表数据过大的检索瓶颈。简单来说，前者是集群模式，而后者是分布式模式，因此无论从任何一个维度来看，Sharding无疑是当下互联网最好的选择。

## 1.3 shark简介
shark是一个开源、分布式、轻量级的Mysql分库分表中间件，其具备丰富的Sharding算法支持(2类4种分布式分片算法)，能够方便DBA实现库的水平扩容和降低数据迁移成本。Shark站在巨人的肩膀上(spring jdbc)，采用与应用集成架构，放弃通用性，只为换取更好的执行性能与降低分布式环境下外围系统的宕机风险。

## 1.4 常见的sharding中间件对比
目前市面上的分库分表中间件并不多，并且大部分都是基于Proxy架构，在对于不看重通用性的应用场景下，早期基于应用集成架构的中间件比较成熟的则只有淘宝的TDDL，但TDDL并非是完美的，其弊端同样明显，比如：社区并不活跃、技术文档资料匮乏、臃肿的鸡肋功能，再加上并不开源，因此注定了TDDL无法为欣赏它的非淘宝系用户服务。而Shark孕育而生的目的正是为了填补应用集成集成架构场景下的空白。目前常见的一些Shardig中间件产品对，如下所示：<br>
![](http://dl.iteye.com/upload/picture/pic/135375/24179f14-8f61-35c3-bd8d-f9ca59df4886.jpg)

基于Proxy架构的Sharding中间件，基本上都衍生自Cobar，并且这类产品对分片算法的支持都有限。具体使用什么样的sharding中间件产品，还需要根据具体的应用场景而定，当然如果你并不看重通用性，使用Shark是非常好的选择。

## 1.5 从maven中央仓库下载shark的构件
shark构件从1.3.8版本之后已经可以从maven中央仓库中进行下载，生产中建议使用shark1.4.0后的版本。
```Xml
<dependency>
    <groupId>com.sharksharding</groupId>
    <artifactId>shark</artifactId>
    <version>1.4.0</version>
</dependency>
```

## 1.6 shark依赖的其它maven构件
shark项目中目前所依赖的构件，如下所示：
```Xml
<properties>
    <java-version>1.7</java-version>
    <org.springframework-version>3.2.13.RELEASE</org.springframework-version>
    <org.aspectj-version>1.6.10</org.aspectj-version>
    <org.slf4j-version>1.6.6</org.slf4j-version>
    <commons-dbcp.version>1.4</commons-dbcp.version>
    <commons-pool.version>1.6</commons-pool.version>
    <commons-logging.version>1.2</commons-logging.version>
    <commons-io.version>2.4</commons-io.version>
    <commons-lang3.version>3.4</commons-lang3.version>
    <cglib-version>2.1.3-201003011305</cglib-version>
    <aspectjweaver-version>1.8.5</aspectjweaver-version>
    <servlet-api-version>2.5</servlet-api-version>
    <fastjson-version>1.2.5</fastjson-version>
    <junit-version>4.7</junit-version>
    <zookeeper-version>3.4.6</zookeeper-version>
    <jedis.version>2.6.2</jedis.version>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
</properties>
```

## 1.7 下载并编译shark源码
shark的源码地址为:https://github.com/gaoxianglong/shark.git
，当成功下载好shark的源码后，可以使用如下命令进行编译：
```Xml
mvn compile
mvn test-compile
```

## 1.8 shark的架构模型
数据路由任务无非就是根据Sharding算法对持有的多数据源进行动态切换，这是任何分库分表中间件的核心功能。使用Shark后，应用层将会持有N个数据源，Shark通过ShardKey进行运算，然后通过Route技术对数据库和数据表进行读/写操作。由于Shark内部并没有实现自己的DBConnectionPool，这就意味着，开发人员可以随意切换DBConnectionPool产品，如果你觉得C3P0没有BonePC性能高，那么你可以切换为BonePC，或者如果你觉得BonePC不够稳定，你又可以切换为druid。

对于开发人员而言，并不需要关心底层的数据库架构，业务逻辑中任何的CRUD操作，都像是在操作单个数据库、单个业务表一样，并且读写效率还不能够比之前低太多(几毫秒之内完成)，而Shark就承担着这样一个任务。Shark所处的领域模型定位，如下所示：<br>
![](http://dl.iteye.com/upload/picture/pic/135379/41d2760b-c857-3d5b-a5b6-5793b1f4ae3d.jpg) 

Shark的领域模型介于持久层和JDBC之间，也就是位于数据路由层。Shark站在巨人的肩膀上，这个巨人正是Spring。简单来说，Shark重写了Spring的JdbcTemplate，并使用AbstractRoutingDataSource作为动态数据源层。因此从另一个侧面反应出了Shark的源码注定是简单、轻量、易阅读、易维护的，因为Shark的核心只做分库分表。我们知道一般的Shading中间件，动不动就上千个类和几十万行代码，其中“猫腻”太多，不仅DBConnectionPool需要自己实现、动态数据源需要自己实现，再加上一些杂七杂八的功能，比如：通用性支持、多种类型的RDBMS或者Nosql支持，那么代码自然臃肿，可读性差。而阅读Shark的代码将会非常轻松和优雅。Shark的3层架构，如下所示：<br>
![](http://dl.iteye.com/upload/picture/pic/133889/274e2a9c-c0ce-3c25-a17a-f1f914ca4667.jpg) 

既然Shark只考虑最核心的Sharding功能，同时也就意味着它的性能恒定指标还需要结合其它第三方产品，比如Shark的动态数据源层所使用的 DBConnectionPool可以为druid，也可以为BonePC。你别指望Shark还能为你处理边边角角的零碎琐事，想要什么效果，自行组合配置，这就是Shark，一个开源、分布式、轻量级的Mysql分库分表中间件。Shark的应用总体架构，如下所示： 
![](http://dl.iteye.com/upload/picture/pic/135377/ca8ecf67-660b-3e4d-ab5a-7abf01551b3e.jpg) <br>

## 1.9 shark的分片算法
- 库内分片类型：
  - 片名连续的库内分片算法；
  - 非片名连续的库内分片算法；
- 一库一片类型：
  - 片名连续的一库一片算法；
  - 非片名连续的一库一片算法；

## 1.10 单表查询支持的sql模板
任何一条sql语句，只要携带路由条件，shark都支持，除了多表查询和子表查询外。目前一些大型互联网公司，比如淘宝、京东、云集微店的数据库方案均是单表sql查询，单表查询比多表联合查询性能慢不了多少，为了扩展性，牺牲一点性能(往返连接、资源消耗等)没什么大不了，so what？互联网场景下，利用单表sql换来的优势有3点：
- 查询条件简单、易于开理解和维护；
- 扩展性极强；
- 缓存利用率高；

## 1.11 shark使用过程中的一些注意事项
- 不支持强一致性的分布式事务，建议在业务层采用依赖MQ、异步操作等方式实现事物，保证事物的最终一致性；
- 不建议、不支持多表查询，所有多表查询sql，务必全部打散为单条sql逐条执行；
- sql语句的第一个参数务必是路由条件；
- 不支持sql语句中出现数据库别名；
- 路由条件必须是整数类型；

## 2、配置读写分离操作
com.sharksharding.core.shard.SharkJdbcTemplate是Shark提供jdbc模板，继承自org.springframework.jdbc.core.JdbcTemplate。简单来说，SharkJdbcTemplate支持除批量操作外JdbcTemplate的所有原生方法。对于开发人员而言，只需要将Spring的JdbcTemplate替换为Shark的SharkJdbcTemplate即可，除此之外，业务逻辑代码中不再有任何的侵入。

数据库的主从配置，即可一主一从，也可一主多从，但目前Shark仅支持一主一从模式。读写分离配置，如下所示：
```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<context:component-scan base-package="com.sharksharding.core">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<!-- 读写分离配置 -->
<bean id="jdbcTemplate" class="com.sharksharding.core.shard.SharkJdbcTemplate"
	init-method="init">
	<property name="isShard" value="false" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r1w0" />
</bean>
<bean id="dataSourceGroup" class="com.sharksharding.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<entry key="0" value-ref="dataSource1" />
			<entry key="1" value-ref="dataSource2" />
		</map>
	</property>
</bean>
<bean id="dataSource1" class="com.mchange.v2.c3p0.ComboPooledDataSource"
	destroy-method="close">
<!-- 省略数据源配置 -->
</bean>
<bean id="dataSource2" class="com.mchange.v2.c3p0.ComboPooledDataSource"
	destroy-method="close">
<!-- 省略数据源配置 -->
</bean>
```
上述程序实例中，SharkDatasourceGroup就是一个用于管理多数据源的Group，继承自org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource，它充当了shark动态数据源层的角色，由此基础之上实现DBRoute。

在SharkJdbcTemplate中，属性isShard定义了Sharding开关，缺省为false，也就意味着缺省是没有开启分库分表的，那么在不Sharding的情况下，我们依然可以使用shark来完成读写分离操作。wr_index属性定义了读写分离的起始索引，也就是说，有多少个master，就一定需要有等量的slave，比如：master有1个，slave也应该是1个，因此SharkDatasourceGroup中持有的数据源总个数就应该一共是2个，索引从0-1，如果主库的索引为0，那么从库的索引就应该为1，也就是“r1w0”。当配置完成后，一旦shark监测到程序中所执行的sql为写操作时，就会自动切换为master的数据源，反之切换为slave的数据源。

当配置好shark的读写分离后，程序中便可以对SharkJdbcTemplate自动装配，如下所示：
```Java
@Resource
private SharkJdbcTemplate jdbcTemplate;
```
shark的启动日志：
![](http://dl.iteye.com/upload/picture/pic/135381/a9d5b910-34eb-364c-9dbe-e115405530ca.jpg)

## 2.1、sql编写注意事项
sql语句的第一个参数必须是shardkey。耦合在业务代码中的sql语句，如下所示：
```Sql
insert into tab(c1,c2) values(?,?)，
```
上述写法shark是不支持的，约定写法，如下所示：
```Sql
insert into tab(c1,c2) values("+ c1 +",?)
```
也就是说，第一个参数不允许是占位符，而必须是实际参数。在某些情况下，我们可能不太希望将sql耦合在我们的业务代码中，这种情况下，shark提供有类似于mybatis的做法，将sql定义在配置文件中。详情请见3.1小结。

## 3、配置sharding操作
如果你觉得使用shark配置读写分离后并不能够满足场景需要，那么你可以使用本节的sharding配置。

## 3.1 数据库sharding后带来的影响
- ACID无法保证；
- 不支持多表查询；
- 无法继续使用外键约束；
- 无法继续使用单库单表自增序列生成唯一id；

## 3.2 配置sql文件与逻辑代码结构
在某些情况下，我们不太希望将sql语句耦合在业务逻辑代码中，因为这样不利于维护。因此shark提供有类似于mybatis的做法，将sql定义在配置文件中以此达到降低耦合的目的。shark将sql文件定义在properties文件中，采用key-value的方式，key建议定义为持久层的方法名称，value为具体的sql语句。sql写法，如下所示：
```Sql
addTab=insert into tab(c1,c2) values(?,?)
```
sql文件的配置方式，如下所示：
```Xml
<bean class="com.sharksharding.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path"
		value="classpath:properties/sql.properties" />
</bean>
```
除了允许定义加载classpath下的sql配置文件外，shrak还允许加载文件路径下的sql配置文件。使用方式如下所示：
```Java
@Resource
private SharkJdbcTemplate jdbcTemplate;
@Resource
private PropertyPlaceholderConfigurer property;

@Override
public void addTab(long shardKey) {
    final String SQL = property.getSql("addTab", shardKey);
    jdbcTemplate.update(SQL);
}
```
上述程序示例中，PropertyPlaceholderConfigurer的getSql()方法的第一个参数就是定义在properties中的key，而shardKey就是路由条件。

## 3.3 一库一片算法
shark支持2种一库一片分布式分片算法，分别为片名连续的一库一片算法和非片名连续的一库一片算法。

## 3.3.1 片名连续的一库一片操作
假设dbSize是1024，tbSize是1024，那么每一个库的片数为1024/1024=1，而片名是按照0000-1023进行分布的， 这就意味着片名是全局唯一的，不允许出现重复。相对于库内分片，一库一片的算法更简单和直观，因为一库一片只跟库相关与片无关，算出了库就等于间接算出了片。如下所示：<br>
![](http://dl.iteye.com/upload/picture/pic/135383/775398ce-33cc-3085-ab4f-9c32849a2bae.jpg)

配置信息，如下所示：
```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<context:component-scan
	base-package="com.sharksharding.core,com.test.sharksharding.use1">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<bean id="jdbcTemplate" class="com.sharksharding.core.shard.SharkJdbcTemplate"
	init-method="init">
	<property name="isShard" value="true" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r1024w0" />
	<property name="shardMode" value="true" />
	<property name="consistent" value="true" />
	<property name="dbRuleArray" value="#uid|email_hash# % 1024" />
	<property name="tbSuffix" value="_0000" />
</bean>
<bean id="dataSourceGroup" class="com.sharksharding.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<!-- 省略引用2048个数据源配置 -->
		</map>
	</property>
</bean>
<bean class="com.sharksharding.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path"
		value="classpath:properties/sql.properties" />
</bean>
<!-- 省略2048个数据源配置 -->
```

上述程序示例中，主库一共是1024个(1024个子表，每个库包含子表数为1个)，那么自然从库也就是1024个，在SharkDatasourceGroup中一共会持有2048个数据源，数据源索引为0-2048。

在SharkJdbcTemplate中，属性isShard定义了sharding开关,true为开启。属性wr_index定义了读写分离的起始索引，这也就意味着0-1023都是master，而1024-2047都是slave，一旦shark监测到程序中所执行的sql为写操作时，就会自动切换为master的数据源，反之切换为slave的数据源(当然如果不希望配置slave，那么属性wr_index应该定义为r0w0)。属性shardMode定义了需要使用shark的哪一种分片算法，true为一库一片，而false则为库内分片。属性consistent定义了片名是否连续，true为片名连续,false为非片名连续。属性dbRuleArray定义了分库规则，其中一共包含有2个shardkey，分别为uid和email_hash，然后再%dbSize便可计算出数据究竟应该落盘到哪个片内。tbSuffix属性指明了子库和子表的后缀。

如果sql语句中的第一个参数并不是shardkey时，shark将会抛出下述异常信息：
```Java
com.sharksharding.exception.SqlParserException: can not find shardkey
```

## 3.3.2 非片名连续的一库一片操作
假设dbSize是1024，tbSize是1024，那么每一个库的片数为1024/1024=1，非片名连续的一库一片算法，所有片名全局一致，所有片名无需后缀。
![](http://dl.iteye.com/upload/picture/pic/135385/c562c14b-6ff7-3de8-bb34-59f370d64f76.jpg)

配置信息，如下所示：
```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<context:component-scan
	base-package="com.sharksharding.core,com.test.sharksharding.use1">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<bean id="jdbcTemplate" class="com.sharksharding.core.shard.SharkJdbcTemplate"
	init-method="init">
	<property name="isShard" value="true" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r1024w0" />
	<property name="shardMode" value="true" />
	<property name="consistent" value="false" />
	<property name="dbRuleArray" value="#uid|email_hash# % 1024" />
	<property name="tbSuffix" value="_0000" />
</bean>
<bean id="dataSourceGroup" class="com.sharksharding.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<!-- 省略引用2048个数据源配置 -->
		</map>
	</property>
</bean>
<bean class="com.sharksharding.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path"
		value="classpath:properties/sql.properties" />
</bean>
<!-- 省略2048个数据源配置 -->
```

上述程序示例中，主库一共是1024个(1024个子表，每个库包含子表数为1个)，那么自然从库也就是1024个，在SharkDatasourceGroup中一共会持有2048个数据源，数据源索引为0-2048。

在SharkJdbcTemplate中，属性isShard定义了sharding开关,true为开启。属性wr_index定义了读写分离的起始索引，这也就意味着0-1023都是master，而1024-2047都是slave，一旦shark监测到程序中所执行的sql为写操作时，就会自动切换为master的数据源，反之切换为slave的数据源(当然如果不希望配置slave，那么属性wr_index应该定义为r0w0)。属性shardMode定义了需要使用shark的哪一种分片算法，true为一库一片，而false则为库内分片。属性consistent定义了片名是否连续，true为片名连续,false为非片名连续。属性dbRuleArray定义了分库规则，其中一共包含有2个shardkey，分别为uid和email_hash，然后再%dbSize便可计算出数据究竟应该落盘到哪个片内。tbSuffix属性指明了子库的后缀。

如果sql语句中的第一个参数并不是shardkey时，shark将会抛出下述异常信息：
```Java
com.sharksharding.exception.SqlParserException: can not find shardkey
```

## 3.4 库内分片算法
shark支持2种库内分片分布式分片算法，分别为片名连续的库内分片算法和非片名连续的库内分片算法。

## 3.4.1 片名连续的库内分片操作
假设dbSize是32，tbSize是1024，那么每一个库的片数为1024/32=32，片名是按照0000-1023进行分布的，这就意味着片名是全局唯一的，不允许出现重复。<br>
![](http://dl.iteye.com/upload/picture/pic/135389/da3425d9-d970-3719-8e56-c20c409a4f16.jpg)

配置信息，如下所示：
```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<context:component-scan
	base-package="com.sharksharding.core,com.test.sharksharding.use1">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<bean id="jdbcTemplate" class="com.sharksharding.core.shard.SharkJdbcTemplate"
	init-method="init">
	<property name="isShard" value="true" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r32w0" />
	<property name="shardMode" value="false" />
	<property name="consistent" value="true" />
	<property name="dbRuleArray" value="#uid|email_hash# % 1024 / 32" />
	<property name="tbRuleArray" value="#uid|email_hash# % 1024 % 32" />
	<property name="tbSuffix" value="_0000" />
</bean>
<bean id="dataSourceGroup" class="com.sharksharding.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<!-- 省略引用64个数据源配置 -->
		</map>
	</property>
</bean>
<bean class="com.sharksharding.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path"
		value="classpath:properties/sql.properties" />
</bean>
<!-- 省略64个数据源配置 -->
```

上述程序示例中，主库一共是32个(1024个子表，每个库包含子表数为32个)，那么自然从库也就是32个，在SharkDatasourceGroup中一共会持有64个数据源，数据源索引为0-63。

在SharkJdbcTemplate中，属性isShard定义了sharding开关,true为开启。属性wr_index定义了读写分离的起始索引，这也就意味着0-31都是master，而32-63都是slave，一旦shark监测到程序中所执行的sql为写操作时，就会自动切换为master的数据源，反之切换为slave的数据源(当然如果不希望配置slave，那么属性wr_index应该定义为r0w0)。属性shardMode定义了需要使用shark的哪一种分片算法，true为一库一片，而false则为库内分片。属性consistent定义了片名是否连续，true为片名连续,false为非片名连续。属性dbRuleArray定义了分库规则，其中一共包含有2个shardkey，分别为uid和email_hash，然后再%dbSize便可计算出数据究竟应该落盘到哪个片内。tbSuffix属性指明了子库的后缀。

如果sql语句中的第一个参数并不是shardkey时，shark将会抛出下述异常信息：
```Java
com.sharksharding.exception.SqlParserException: can not find shardkey
```

## 3.4.2 非片名连续的库内分片操作
假设dbSize是32，tbSize是1024，那么每一个库的片数为1024/32=32，片名在每一个库中都是按照0-31进行分布的，非全局唯一，这样的好处，相对于片名连续的库内分片更容易扩容和数据迁移。<br>
![](http://dl.iteye.com/upload/picture/pic/135387/280b2b39-7d48-323b-955a-cc210f285597.jpg)

配置信息，如下所示：
```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<context:component-scan
	base-package="com.sharksharding.core,com.test.sharksharding.use1">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<bean id="jdbcTemplate" class="com.sharksharding.core.shard.SharkJdbcTemplate"
	init-method="init">
	<property name="isShard" value="true" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r32w0" />
	<property name="shardMode" value="false" />
	<property name="consistent" value="false" />
	<property name="dbRuleArray" value="#uid|email_hash# % 1024 / 32" />
	<property name="tbRuleArray" value="#uid|email_hash# % 1024 % 32" />
	<property name="tbSuffix" value="_0000" />
</bean>
<bean id="dataSourceGroup" class="com.sharksharding.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<!-- 省略引用64个数据源配置 -->
		</map>
	</property>
</bean>
<bean class="com.sharksharding.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path"
		value="classpath:properties/sql.properties" />
</bean>
<!-- 省略64个数据源配置 -->
```

上述程序示例中，主库一共是32个(1024个子表，每个库包含子表数为32个)，那么自然从库也就是32个，在SharkDatasourceGroup中一共会持有64个数据源，数据源索引为0-63。

在SharkJdbcTemplate中，属性isShard定义了sharding开关,true为开启。属性wr_index定义了读写分离的起始索引，这也就意味着0-31都是master，而32-63都是slave，一旦shark监测到程序中所执行的sql为写操作时，就会自动切换为master的数据源，反之切换为slave的数据源(当然如果不希望配置slave，那么属性wr_index应该定义为r0w0)。属性shardMode定义了需要使用shark的哪一种分片算法，true为一库一片，而false则为库内分片。属性consistent定义了片名是否连续，true为片名连续,false为非片名连续。属性dbRuleArray定义了分库规则，其中一共包含有2个shardkey，分别为uid和email_hash，然后再%dbSize便可计算出数据究竟应该落盘到哪个片内。tbSuffix属性指明了子库的后缀。

如果sql语句中的第一个参数并不是shardkey时，shark将会抛出下述异常信息：
```Java
com.sharksharding.exception.SqlParserException: can not find shardkey
```

## 3.5 自动生成数据源文件
为了避免手工配置出现错误的情况，shark提供有自动生成sharding配置文件和数据源配置文件的功能(支持druid和c3p0)。 

## 3.5.1 自动生成sharding配置文件
假设采用片名连续的库内分片模式，32个库1024个表，使用com.sharksharding.util.xml.CreateCoreXml进行生成，如下所示：
```Java
public @Test void testCreateCoreXml() {
    CreateCoreXml c_xml = new CreateCoreXml();
    /* 是否控制台输出生成的配置文件 */
    c_xml.setIsShow(true);
    c_xml.setDbSize("64");
    c_xml.setShard("true");
    c_xml.setWr_index("r0w32");
    c_xml.setShardMode("false");
    c_xml.setConsistent("true");
    c_xml.setDbRuleArray("#uid|email_hash# % 1024 / 32");
    c_xml.setTbRuleArray("#uid|email_hash# % 1024 % 32");
    c_xml.setSqlPath("classpath:properties/sqlFile.properties");
    /* 执行配置文件输出 */
    Assert.assertTrue(c_xml.createCoreXml(new File("c:/shark-context.xml")));
}
```

## 3.5.2 自动生成c3p0数据源文件
使用com.sharksharding.util.xml.CreateCoreXml进行生成，如下所示：
```Java
public @Test void testCreateC3p0Xml() {
	CreateC3p0Xml c_xml = new CreateC3p0Xml();
	/* 是否控制台输出生成的配置文件 */
	c_xml.setIsShow(true);
	c_xml.setTbSuffix("_0000");
	c_xml.setDataSourceIndex(1);
	c_xml.setDbSize("16");
	c_xml.setJdbcUrl("jdbc:mysql://ip1:3306/db");
	c_xml.setUser("${name}");
	c_xml.setPassword("${password}");
	c_xml.setDriverClass("${driverClass}");
	c_xml.setInitialPoolSize("${initialPoolSize}");
	c_xml.setMinPoolSize("${minPoolSize}");
	c_xml.setMaxPoolSize("${maxPoolSize}");
	c_xml.setMaxStatements("${maxStatements}");
	c_xml.setMaxIdleTime("${maxIdleTime}");
	/* 执行配置文件输出 */
	Assert.assertTrue(c_xml.createDatasourceXml(new File("c:/dataSource-context.xml")));
}
```

## 3.5.3 自动生成druid数据源文件
使用com.sharksharding.util.xml.CreateCoreXml进行生成，如下所示：
```Java
public @Test void testCreateDruidXml() {
	CreateDruidXml c_xml = new CreateDruidXml();
	/* 是否控制台输出生成的配置文件 */
	c_xml.setIsShow(true);
	/* 数据源索引起始 */
	c_xml.setDataSourceIndex(1);
	/* 配置分库分片信息 */
	c_xml.setDbSize("16");
	/* false为懒加载模式，反之启动时开始初始化数据源 */
	c_xml.setInit_method(true);
	c_xml.setTbSuffix("_0000");
	/* 生成数据源信息 */
	c_xml.setUsername("${username}");
	c_xml.setPassword("${password}");
	c_xml.setUrl("jdbc:mysql://ip1:3306/db");
	c_xml.setInitialSize("${initialSize}");
	c_xml.setMinIdle("${minIdle}");
	c_xml.setMaxActive("${maxActive}");
	c_xml.setPoolPreparedStatements("${poolPreparedStatements}");
	c_xml.setMaxOpenPreparedStatements("${maxOpenPreparedStatements}");
	c_xml.setTestOnBorrow("${testOnBorrow}");
	c_xml.setTestOnReturn("${testOnReturn}");
	c_xml.setTestWhileIdle("${testWhileIdle}");
	c_xml.setFilters("${filters}");
	c_xml.setConnectionProperties("${connectionProperties}");
	c_xml.setUseGlobalDataSourceStat("${useGlobalDataSourceStat}");
	c_xml.setTimeBetweenLogStatsMillis("${timeBetweenLogStatsMillis}");
	/* 执行配置文件输出 */
	Assert.assertTrue(c_xml.createDatasourceXml(new File("e:/dataSource-context.xml")));
}
```