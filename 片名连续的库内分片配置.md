```Xml
<aop:aspectj-autoproxy proxy-target-class="true" />
<!-- 自动扫描 -->
<context:component-scan base-package="com">
	<context:include-filter type="annotation"
		expression="org.aspectj.lang.annotation.Aspect" />
</context:component-scan>
<!-- 片名连续的库内分片配置 -->
<bean id="jdbcTemplate" class="com.gxl.shark.core.shard.SharkJdbcTemplate">
	<constructor-arg name="isShard" value="true" />
	<property name="dataSource" ref="dataSourceGroup" />
	<property name="wr_index" value="r0w0" />
	<!-- 分片模式,false为库内分片模式,true为一库一表分片模式 -->
	<property name="shardMode" value="false" />
	<!-- 片名是否连续,true为片名连续,false为非片名连续 -->
	<property name="consistent" value="true" />
	<property name="dbRuleArray" value="#userinfo_test_id|email_hash# % 4 / 2" />
	<property name="tbRuleArray" value="#userinfo_test_id|email_hash# % 4 % 2" />
	<property name="tbSuffix" value="_0000" />
</bean>
<bean id="dataSourceGroup" class="com.gxl.shark.core.config.SharkDatasourceGroup">
	<property name="targetDataSources">
		<map key-type="java.lang.Integer">
			<entry key="0" value-ref="dataSource1" />
			<entry key="1" value-ref="dataSource2" />
		</map>
	</property>
</bean>
<bean class="com.gxl.shark.sql.PropertyPlaceholderConfigurer">
	<constructor-arg name="path" value="classpath:sql.properties" />
</bean>
```

上述程序示例中，使用的是一主一从的片名连续的库内分片配置。主库一共是32个(1024个子表，每个库包含子表数为32个)，那么自然从库也就是 32个，在SharkDatasourceGroup中一共会持有64个数据源，数据源索引为0-63。那么在SharkJdbcTemplate中 首先要做的事情是将分库分片开关打开，然后主从索引wr_index属性的比例是“r32w0”，这也就意味着0-31都是主库，而32-63都是从 库，Kratos会根据这个索引来自动根据所执行的操作切换到对应的主从数据源上。属性shardMode其实就是指明了需要Shark使用哪一种分片 算法，true为一库一片，而false则为库内分片。

属性dbRuleArray指明了分库规则，“#userinfo_id|email_hash# % 1024 / 32”指明了路由条件可能包括两个，分别为userinfo_id和email_hash。然后根据路由条件先%tbSize，最后在/dbSize，即 可计算出具体的数据源。在此大家需要注意，库的倍数一定要是表的数量，否则数据将无法均匀分布到所有的子表上。或许大家有个疑问，为什么路由条件会有多个 呢？这是因为在实际的开发过程中，我们所有的查询条件都需要根据路由条件来，并且实际情况不可能只有一个路由条件，甚至有可能更多(比如反向索引表)。因 此通过符号“|”分隔开多个路由条件。当一条sql执行时，Kratos会匹配sql条件中的第一个数据库参数字段是否是分库分表条件，如果不是则会抛出 异常com.gxl.shark.exception.ShardException。分表规则“#userinfo_id|email_hash# % 1024 % 32”其实大致和分库规则一样，只不过最后并非是/dbSize，而是%dbSize。经过分库分表算法后，一条sql就会被解析并落盘到具体的库和具体 的表中。